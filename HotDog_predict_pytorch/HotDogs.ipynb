{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197d366f",
   "metadata": {},
   "source": [
    "Данные для модели\n",
    "\"https://storage.googleapis.com/dlcourse_ai/train.zip\"\n",
    "\"https://storage.googleapis.com/dlcourse_ai/test.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e943efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ff6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963cf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2class(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_dir:str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path_dir = path_dir #путь к папке\n",
    "        self.dir_list = sorted(os.listdir(path_dir)) #список файлов\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.dir_list) # инициализация длины\n",
    "    \n",
    "    def __getitem__(self,idx): #возврат нужного изображения по индексу и его метки класса\n",
    "        \n",
    "        class_id = 1 if 'frankfurter' in self.dir_list[idx] or 'chili-dog' in self.dir_list[idx] or 'hotdog' in self.dir_list[idx] else 0\n",
    "        \n",
    "        img_path = os.path.join(self.path_dir, self.dir_list[idx])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR) #в матрицу\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # нужная кодировка\n",
    "        img = img.astype(np.float32) # во флоат для модели\n",
    "        img = img/255.0 # нормализация\n",
    "        \n",
    "        img = cv2.resize(img, (64,64), interpolation = cv2.INTER_AREA) #сжатие и интерполяция\n",
    "        \n",
    "        img = img.transpose((2,0,1)) # каналы, высота, ширина\n",
    "        \n",
    "        t_img = torch.from_numpy(img) # в тензор\n",
    "        \n",
    "        t_class_id = torch.tensor(class_id) # индекс в тензор\n",
    "        #return img\n",
    "        return {'img':t_img, 'label':t_class_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c929f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'.\\train_kaggle'\n",
    "test_path = r'.\\test_kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b98224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_hotdogs = Dataset2class(train_path)\n",
    "test_ds_hotdogs = Dataset2class(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4a4274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4603, 1150)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds_hotdogs), len(test_ds_hotdogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af89edbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(train_ds_hotdogs[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cd667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ff967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds_hotdogs, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    \n",
    "    shuffle = True,\n",
    "    drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds_hotdogs, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    \n",
    "    shuffle = False,\n",
    "    drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20166dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.conv0 = nn.Conv2d(3,32,3, stride = 1, padding = 0) # каналы было, каналов стало, размер ядра\n",
    "        self.conv1 = nn.Conv2d(32,32,3, stride = 1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(32,64,3, stride = 1, padding = 0)\n",
    "        self.conv3 = nn.Conv2d(64,128,3, stride = 1, padding = 0)\n",
    "        \n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1)) # сворачивание средним до 1х1\n",
    "        self.flatten = nn.Flatten() # в вектор\n",
    "        self.linear1 = nn.Linear(128,64) # линейное преобразование \n",
    "        self.linear2 = nn.Linear(64,16)\n",
    "        self.linear3 = nn.Linear(16,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.act(out)\n",
    "        \n",
    "        out = self.adaptivepool(out)\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        out = self.linear1(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.linear2(out)\n",
    "        out = self.act(out)\n",
    "        \n",
    "        out = self.linear3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ccc859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb2e9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "299b5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (act): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (linear3): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ec8ffb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111826"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b47f7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15a89b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(task='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fc2ac19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10370477588249c3877f0019b4585e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5743002699434965\n",
      "accuracy = tensor(0.6863)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9ad74212448a5bb9a64a3d61bd12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5196866001090106\n",
      "accuracy = tensor(0.7060)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd6a7874b8b41bb8a2e51510b1702b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5121739105376633\n",
      "accuracy = tensor(0.7113)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ad08efbc7847fcbddeb874fe911ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5134191083679631\n",
      "accuracy = tensor(0.7180)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ee167af8e045ed8056a1a58f58d3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.48272849899758863\n",
      "accuracy = tensor(0.7353)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    \n",
    "    for sample in tqdm(train_loader):\n",
    "        img, label = sample['img'], sample['label']\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "        \n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "        \n",
    "    #pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "    print('loss =', loss_val/len(train_loader))\n",
    "    print('accuracy =', acc_val/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccf971de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff8a91e842045148d1e7dc598fb3d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.3611502595659759\n",
      "accuracy = tensor(0.8996)\n"
     ]
    }
   ],
   "source": [
    "loss_val = 0\n",
    "acc_val = 0\n",
    "\n",
    "for sample in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        img, label = sample['img'], sample['label']\n",
    "\n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "\n",
    "#pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "print('loss =', loss_val/len(test_loader))\n",
    "print('accuracy =', acc_val/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d92d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa6209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881d8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e5960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ba926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
